---
layout: default
title: Weighty Hamming weights
tags: [algorithms, optimization, hamming weight, bit hack]
---

I recently got myself a copy of Jon Bentley's <a alt="Programming Pearls on Amazon" href="http://www.amazon.com/Programming-Pearls-2nd-Jon-Bentley/dp/0201657880/">Programming Pearls</a>, which I will review in an upcoming post. It's been quite an instructive reading, and I've been trying hard to pace myself, understanding the examples and working out some of the problems at the end of each Column without rushing through the pages.

Having just finished Part II of the book, which overviews several interesting principles for improving the performance of a program, from choice of algorithms and data structures to low-level code tuning, I thought I'd try to apply some of these concepts in a thorough resolution of a proposed problem.

The problem in question is the 7th of Column 9, which asks:

<blockquote>
Given a very long sequence (say, billions or trillions) of bytes, how would you efficiently count the total number of one bits? (That is, how many bits are turned on in the entire sequence?)
</blockquote>

The count of one bits in a binary string is known as its <a alt="Hamming weight on Wikipedia" href="http://en.wikipedia.org/wiki/Hamming_weight">Hamming weight</a>, so the problem could also be stated as requiring the Hamming weight of a big string of bits.

The Hamming weight of a binary string may play an important role in applications in which each bit encodes information about a distinct entity, and one wishes to count entities with a given property. For instance, given a filesystem bitmap which encodes used and free blocks as zero and one bits, respectively, the Hamming distance can be used to calculate the amount of free disk space.

There are known and obscure techniques for making such calculation. In particular, the thread <a alt="Best algorithm to count the number of set bits in a 32 bit integer" href="http://stackoverflow.com/questions/109023/best-algorithm-to-count-the-number-of-set-bits-in-a-32-bit-integer">Best algorithm to count the number of set bits in a 32-bit integer</a> on Stack Overflow abounds with solutions for strings of 32 bits.

I approached the problem by first creating a 2.8Gib file of random bits to serve as input for my algorithms. Then, I attempted to solve the problem by using a lookup table of bit counts so as to avoid having to iterate through each of the input bits and maybe take advantage of caching for the lookup table. This is the resulting C code:

{% highlight c linenos %}
{% include snippets/hamming_weight_lut.c %}
{% endhighlight %}

Basically, lines 7 to 24 define a precomputed table mapping each possible value of a byte to its Hamming weight. I then read the input file in chunks into a buffer, and for each byte in each chunk, look up its Hamming weight in the table and accumulate that value into a variable. Notice how the chunk size (BUFSIZE) is intentionally left unefined in the code -- I'll plug the value in at compilation time.

For comparison purposes, I also implemented Brian Kernighan's very elegant bit-clearing method for achieving the same purpose in the inner loop, resulting in the following code:

{% highlight c linenos %}
{% include snippets/hamming_weight_bk.c %}
{% endhighlight %}

This method iterates through each byte of the input, and clears the less significant bit in it (with the clever expression b &= b - 1) as long as the byte's value is not zero. The count of how many bits were cleared in that byte is of course its Hamming weight.

Needless to say, both programs compute the exact same amount of one bits in my data sample. But let's have a look at their performances.

One important lesson from Column 6 of the book is that performance can often be achieved by tuning the program at several different design levels, from high level algorithmic choices down to system-dependent code tweaks and hardware upgrades.

For this problem, both programs above are in and of themselves algorithmic improvements over the naive approach of looping through all input bits. So in order to open a new front of attack, I chose to experiment with two lower-level tuning parameters: <a alt="Loop unrolling on Wikipedia" href="http://en.wikipedia.org/wiki/Loop_unrolling">loop unrolling</a> for the inner bit-counting loop, and input chunk size.

I compiled and ran the first program above (which is my actual answer to the problem) using chunk sizes of 512, 1024, 4096 (my filesystem's block size), 8192 (my system's value for BUFSIZ), 12288 and 16384 bytes, with and without loop unrolling. For each test, the running time was measured three times with the shell built-in time command, the first of which on cold cache, and the other two on warm cache.

The tests were conducted on a Core I3 380M notebook with 4GB RAM and using gcc 4.5.3. The compilations were made using -O2 and the loop unrolling was made with the -funroll-loops compilation parameter. I didn't tweak the chunk size of the second program, but I did measure its running time with and without loop unrolling.

Let's see the results for the lookup table method:

<style>
    .test-results-wrapper {
        overflow: auto;
        max-width: 700px;
        padding: 0px;
    }

    table.test-results {
        text-align: center;
        border-collapse: collapse;
        width: 700px;
    }

    table.timings {
        white-space: nowrap;
    }

    img.bracket {
        float: left;
        height: 4em;
    }

    th {
        padding: 0px 20px;
        border-bottom: 1px solid black;
    }

    tr.norow {
        border-bottom: 1px solid black;
    }

    tr.norow:last-child {
        border: none;
    }
</style>

<div class="test-results-wrapper standout">
    <table class="test-results">
        <tr>
            <th>Chunk size (bytes)</th>
            <th>Loop unrolling</th>
            <th>Times (seconds, real/user/sys)</th>
        </tr>

        <tr>
            <td rowspan="2">8</td>
            <td>Yes</td>
            <td>
            <img class="bracket" src="/img/curly.jpg"/>
            <table class="timings">
                <tr><td>2m52.240s / 0m11.791s / 2m38.049s</td></tr>
                <tr><td>2m47.847s / 0m11.893s / 2m35.125s</td></tr>
                <tr><td>2m47.048s / 0m11.934s / 2m34.432s</td></tr>
            </table>
        </td>
    </tr>
    <tr class="norow">
        <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>3m30.076s / 0m12.174s / 3m15.364s</td></tr>
                    <tr><td>3m19.436s / 0m12.514s / 3m5.905s</td></tr>
                    <tr><td>3m18.667s / 0m12.576s / 3m5.227s</td></tr>
                </table>
            </td>
        </tr>

        <tr>
            <td rowspan="2">512</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m29.340s / 0m7.138s / 0m9.451s</td></tr>
                    <tr><td>0m8.360s / 0m2.750s / 0m3.226s</td></tr>
                    <tr><td>0m6.285s / 0m2.631s / 0m3.015s</td></tr>
                </table>
            </td>
        </tr>
        <tr class="norow">
            <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m29.654s / 0m7.075s / 0m10.383s</td></tr>
                    <tr><td>0m5.697s / 0m2.502s / 0m3.184s</td></tr>
                    <tr><td>0m5.636s / 0m2.559s / 0m3.067s</td></tr>
                </table>
            </td>
        </tr>

        <tr>
            <td rowspan="2">1024</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m37.643s / 0m5.719s / 0m4.975s</td></tr>
                    <tr><td>0m4.230s / 0m2.517s / 0m1.706s</td></tr>
                    <tr><td>0m4.162s / 0m2.475s / 0m1.680s</td></tr>
                </table>
            </td>
        </tr>
        <tr class="norow">
            <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m31.443s / 0m6.713s / 0m6.254s</td></tr>
                    <tr><td>0m4.304s / 0m2.444s / 0m1.853s</td></tr>
                    <tr><td>0m4.239s / 0m2.512s / 0m1.719s</td></tr>
                </table>
            </td>
        </tr>

        <tr>
            <td rowspan="2">4096</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m30.454s / 0m6.560s / 0m3.302s</td></tr>
                    <tr><td>0m3.323s / 0m2.420s / 0m0.897s</td></tr>
                    <tr><td>0m3.271s / 0m2.415s / 0m0.849s</td></tr>
                </table>
            </td>
        </tr>
        <tr class="norow">
            <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m30.030s / 0m6.828s / 0m3.726s</td></tr>
                    <tr><td>0m3.361s / 0m2.388s / 0m0.966s</td></tr>
                    <tr><td>0m3.302s / 0m2.398s / 0m0.899s</td></tr>
                </table>
            </td>
        </tr>

        <tr>
            <td rowspan="2">8192</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m29.580s / 0m6.805s / 0m2.963s</td></tr>
                    <tr><td>0m3.193s / 0m2.364s / 0m0.822s</td></tr>
                    <tr><td>0m3.124s / 0m2.389s / 0m0.729s</td></tr>
                </table>
            </td>
        </tr>
        <tr class="norow">
            <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m29.372s / 0m6.784s / 0m3.044s</td></tr>
                    <tr><td>0m3.212s / 0m2.430s / 0m0.775s</td></tr>
                    <tr><td>0m3.144s / 0m2.410s / 0m0.727s</td></tr>
                </table>
            </td>
        </tr>

        <tr>
            <td rowspan="2">12288</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m30.662s / 0m6.507s / 0m2.830s</td></tr>
                    <tr><td>0m3.168s / 0m2.412s / 0m0.750s</td></tr>
                    <tr><td>0m3.096s / 0m2.406s / 0m0.684s</td></tr>
                </table>
            </td>
        </tr>
        <tr class="norow">
            <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m30.096s / 0m6.564s / 0m2.961s</td></tr>
                    <tr><td>0m3.149s / 0m2.430s / 0m0.713s</td></tr>
                    <tr><td>0m3.091s / 0m2.422s / 0m0.662s</td></tr>
                </table>
            </td>
        </tr>

        <tr>
            <td rowspan="2">16384</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m29.446s / 0m6.863s / 0m2.806s</td></tr>
                    <tr><td>0m3.145s / 0m2.380s / 0m0.758s</td></tr>
                    <tr><td>0m3.076s / 0m2.428s / 0m0.642s</td></tr>
                </table>
            </td>
        </tr>
        <tr class="norow">
            <td>No</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m30.313s / 0m6.611s / 0m2.930s</td></tr>
                    <tr><td>0m3.136s / 0m2.409s / 0m0.721s</td></tr>
                    <tr><td>0m3.085s / 0m2.464s / 0m0.614s</td></tr>
                </table>
            </td>
        </tr>
    </table>
</div>

For every chunk size and loop unrolling setting, the table above contains three timing values, the top one being on cold cache and the other two on warm cache.

The running times were mostly the same for all cold cache runs regardless of chunk size, with the real (wall clock) time being much greater than the sum of user and system time. This indicates that the program was largely I/O bound in these runs, which is entirely expected and rules out the effects of the other optimizations.

The other runs show that the timings decreases slowly but surely as the chunk size increases. While I did expect to reach optimal performance around 4096 or maybe 8192 bytes, the fact that the run times continued to decrease after that surprised me a bit. However, the timings for large chunk sizes are pretty close to one another, so the apparent decrease might be just due to system noise.

Loop unrolling did not seem to affect the running times consistently. Although it was enabled on the best run overall (3.076s with chunk size of 16384 bytes), the runner-up (3.085s with the same chunk size) is only 0.009s behind.

Finally, for comparison purposes, I timed the second program above, which employs the bit-clearing method and uses chunks of size BUFSIZ (8192 for me), compiled with loop unrolling, and got the following results:

<div class="test-results-wrapper standout">
    <table class="test-results">
        <tr>
            <th>Chunk size (bytes)</th>
            <th>Loop unrolling</th>
            <th>Times (seconds, real/user/sys)</th>
        </tr>
        <tr>
            <td rowspan="2">8192</td>
            <td>Yes</td>
            <td>
                <img class="bracket" src="/img/curly.jpg"/>
                <table class="timings">
                    <tr><td>0m47.605s / 0m44.523s / 0m1.616s</td></tr>
                    <tr><td>0m45.788s / 0m44.079s / 0m1.070s</td></tr>
                    <tr><td>0m45.554s / 0m44.077s / 0m0.948s</td></tr>
                </table>
            </td>
        </tr>
    </table>
</div>

Wow! This method is almost 15 times slower, and spends most of its time in user space -- it's CPU-bound even in cold cache!

The lookup table method is a lot faster, likely for making good use of the system's caching mechanism and relying on fast array indexing for computing the Hamming weights of individual bytes.

<em>Update (09/02/2012)</em>: Experimenting with different data types for the
bit buffer also gives interesting results. Replacing the array of unsigned chars
with an array of unsigned longs (whose size matches the word size for my machine) reduces the timings for the bit-counting method to 14.425s on warm cache, of which 13.706s are spent in user space.

